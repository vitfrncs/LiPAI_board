{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b644566",
   "metadata": {},
   "source": [
    "## 4 -  Usando o modelo original do notebook:\n",
    "\n",
    "a. Mude o Otimizador: Substitua o otimizador Adam por SGD (Stochastic Gradient Descent). \n",
    "\n",
    "b. Treine o modelo com o SGD.\n",
    "\n",
    "c. O que aconteceu com o custo (loss) durante o treinamento? A acurácia final foi melhor ou pior? O SGD com essa taxa de aprendizado pareceu uma boa escolha?\n",
    "\n",
    "O custo aumentou um pouco durante o treinamento. Antes da alteração, ele se mantinha constante em cerca de 0,693, mas com a mudança na taxa de aprendizado, passou a variar e atingir valores maiores em até aproximadamente 0,2. Com a modificação da learning rate, houve uma melhora na acurácia do modelo que utiliza SGD. No entanto, com a taxa de aprendizado anterior, esse modelo não foi uma boa escolha, pois o custo aumentava e a acurácia final era similar à obtida com o otimizador Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "849a69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caeca134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "feature_names = ['pclass', 'female', 'age', 'fare']\n",
    "titanic['female'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
    "titanic.dropna(subset=feature_names, inplace=True)  #891 para 714\n",
    "\n",
    "X = titanic[feature_names].to_numpy()\n",
    "y = titanic['survived'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7db2f8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de X_train:  (535, 4)\n",
      "Tamanho de X_test:  (179, 4)\n",
      "Tamanho de y_train:  (535,)\n",
      "Tamanho de y_test:  (179,)\n"
     ]
    }
   ],
   "source": [
    "print('Tamanho de X_train: ', X_train.shape)\n",
    "print('Tamanho de X_test: ', X_test.shape)\n",
    "print('Tamanho de y_train: ', y_train.shape)\n",
    "print('Tamanho de y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38504a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassBin(\n",
      "  (linear1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (linear2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (dropout2): Dropout(p=0.2, inplace=False)\n",
      "  (linear3): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (dropout3): Dropout(p=0.2, inplace=False)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ClassBin(nn.Module):\n",
    "    # Construtor\n",
    "    def __init__(self):\n",
    "        super(ClassBin, self).__init__()\n",
    "        self.linear1 = nn.Linear(4, 4)    # primeira hidden layer\n",
    "        self.dropout1 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.linear2 = nn.Linear(4, 4)    # segunda hidden layer\n",
    "        self.dropout2 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.linear3 = nn.Linear(4, 1)    # terceira hidden layer\n",
    "        self.dropout3 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Propagação (Feed Forward)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = ClassBin()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26debc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "epochs = 100\n",
    "batch_size = 32  # X_train 535 / 32 = 16.71 (então são 17 batches de 32)\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instânciar o Otimizador Adam\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17a53922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Converter X e y para torch.Tensor\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "# Um Dataset de Tensores - Array [X, y]\n",
    "train = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce35abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1,\n",
      "          Custo Treino: 0.707\n",
      "Época 2,\n",
      "          Custo Treino: 0.69\n",
      "Época 3,\n",
      "          Custo Treino: 0.692\n",
      "Época 4,\n",
      "          Custo Treino: 0.709\n",
      "Época 5,\n",
      "          Custo Treino: 0.703\n",
      "Época 6,\n",
      "          Custo Treino: 0.693\n",
      "Época 7,\n",
      "          Custo Treino: 0.69\n",
      "Época 8,\n",
      "          Custo Treino: 0.696\n",
      "Época 9,\n",
      "          Custo Treino: 0.696\n",
      "Época 10,\n",
      "          Custo Treino: 0.691\n",
      "Época 11,\n",
      "          Custo Treino: 0.7\n",
      "Época 12,\n",
      "          Custo Treino: 0.7\n",
      "Época 13,\n",
      "          Custo Treino: 0.701\n",
      "Época 14,\n",
      "          Custo Treino: 0.682\n",
      "Época 15,\n",
      "          Custo Treino: 0.69\n",
      "Época 16,\n",
      "          Custo Treino: 0.693\n",
      "Época 17,\n",
      "          Custo Treino: 0.696\n",
      "Época 18,\n",
      "          Custo Treino: 0.695\n",
      "Época 19,\n",
      "          Custo Treino: 0.691\n",
      "Época 20,\n",
      "          Custo Treino: 0.688\n",
      "Época 21,\n",
      "          Custo Treino: 0.685\n",
      "Época 22,\n",
      "          Custo Treino: 0.69\n",
      "Época 23,\n",
      "          Custo Treino: 0.7\n",
      "Época 24,\n",
      "          Custo Treino: 0.695\n",
      "Época 25,\n",
      "          Custo Treino: 0.679\n",
      "Época 26,\n",
      "          Custo Treino: 0.697\n",
      "Época 27,\n",
      "          Custo Treino: 0.705\n",
      "Época 28,\n",
      "          Custo Treino: 0.707\n",
      "Época 29,\n",
      "          Custo Treino: 0.701\n",
      "Época 30,\n",
      "          Custo Treino: 0.697\n",
      "Época 31,\n",
      "          Custo Treino: 0.707\n",
      "Época 32,\n",
      "          Custo Treino: 0.694\n",
      "Época 33,\n",
      "          Custo Treino: 0.701\n",
      "Época 34,\n",
      "          Custo Treino: 0.688\n",
      "Época 35,\n",
      "          Custo Treino: 0.698\n",
      "Época 36,\n",
      "          Custo Treino: 0.702\n",
      "Época 37,\n",
      "          Custo Treino: 0.703\n",
      "Época 38,\n",
      "          Custo Treino: 0.712\n",
      "Época 39,\n",
      "          Custo Treino: 0.7\n",
      "Época 40,\n",
      "          Custo Treino: 0.693\n",
      "Época 41,\n",
      "          Custo Treino: 0.698\n",
      "Época 42,\n",
      "          Custo Treino: 0.708\n",
      "Época 43,\n",
      "          Custo Treino: 0.704\n",
      "Época 44,\n",
      "          Custo Treino: 0.691\n",
      "Época 45,\n",
      "          Custo Treino: 0.699\n",
      "Época 46,\n",
      "          Custo Treino: 0.693\n",
      "Época 47,\n",
      "          Custo Treino: 0.698\n",
      "Época 48,\n",
      "          Custo Treino: 0.684\n",
      "Época 49,\n",
      "          Custo Treino: 0.691\n",
      "Época 50,\n",
      "          Custo Treino: 0.706\n",
      "Época 51,\n",
      "          Custo Treino: 0.703\n",
      "Época 52,\n",
      "          Custo Treino: 0.729\n",
      "Época 53,\n",
      "          Custo Treino: 0.691\n",
      "Época 54,\n",
      "          Custo Treino: 0.686\n",
      "Época 55,\n",
      "          Custo Treino: 0.66\n",
      "Época 56,\n",
      "          Custo Treino: 0.701\n",
      "Época 57,\n",
      "          Custo Treino: 0.691\n",
      "Época 58,\n",
      "          Custo Treino: 0.711\n",
      "Época 59,\n",
      "          Custo Treino: 0.685\n",
      "Época 60,\n",
      "          Custo Treino: 0.699\n",
      "Época 61,\n",
      "          Custo Treino: 0.698\n",
      "Época 62,\n",
      "          Custo Treino: 0.708\n",
      "Época 63,\n",
      "          Custo Treino: 0.703\n",
      "Época 64,\n",
      "          Custo Treino: 0.699\n",
      "Época 65,\n",
      "          Custo Treino: 0.698\n",
      "Época 66,\n",
      "          Custo Treino: 0.696\n",
      "Época 67,\n",
      "          Custo Treino: 0.685\n",
      "Época 68,\n",
      "          Custo Treino: 0.692\n",
      "Época 69,\n",
      "          Custo Treino: 0.697\n",
      "Época 70,\n",
      "          Custo Treino: 0.701\n",
      "Época 71,\n",
      "          Custo Treino: 0.698\n",
      "Época 72,\n",
      "          Custo Treino: 0.695\n",
      "Época 73,\n",
      "          Custo Treino: 0.684\n",
      "Época 74,\n",
      "          Custo Treino: 0.697\n",
      "Época 75,\n",
      "          Custo Treino: 0.687\n",
      "Época 76,\n",
      "          Custo Treino: 0.693\n",
      "Época 77,\n",
      "          Custo Treino: 0.702\n",
      "Época 78,\n",
      "          Custo Treino: 0.685\n",
      "Época 79,\n",
      "          Custo Treino: 0.691\n",
      "Época 80,\n",
      "          Custo Treino: 0.685\n",
      "Época 81,\n",
      "          Custo Treino: 0.695\n",
      "Época 82,\n",
      "          Custo Treino: 0.695\n",
      "Época 83,\n",
      "          Custo Treino: 0.696\n",
      "Época 84,\n",
      "          Custo Treino: 0.719\n",
      "Época 85,\n",
      "          Custo Treino: 0.695\n",
      "Época 86,\n",
      "          Custo Treino: 0.697\n",
      "Época 87,\n",
      "          Custo Treino: 0.703\n",
      "Época 88,\n",
      "          Custo Treino: 0.689\n",
      "Época 89,\n",
      "          Custo Treino: 0.7\n",
      "Época 90,\n",
      "          Custo Treino: 0.696\n",
      "Época 91,\n",
      "          Custo Treino: 0.692\n",
      "Época 92,\n",
      "          Custo Treino: 0.693\n",
      "Época 93,\n",
      "          Custo Treino: 0.691\n",
      "Época 94,\n",
      "          Custo Treino: 0.697\n",
      "Época 95,\n",
      "          Custo Treino: 0.689\n",
      "Época 96,\n",
      "          Custo Treino: 0.704\n",
      "Época 97,\n",
      "          Custo Treino: 0.681\n",
      "Época 98,\n",
      "          Custo Treino: 0.687\n",
      "Época 99,\n",
      "          Custo Treino: 0.706\n",
      "Época 100,\n",
      "          Custo Treino: 0.687\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    model.train() # Colocar o modelo em modo de treinamento (calcula os gradientes)\n",
    "    \n",
    "    # Batch Size\n",
    "    for data in train_loader:\n",
    "        # dar nome aos bois\n",
    "        X = data[0]\n",
    "        y = data[1]\n",
    "        \n",
    "        # Propagação (Feed Forward)\n",
    "        y_pred = model(X)\n",
    "    \n",
    "        # Calcular erro usando a função-custo\n",
    "        # y precisa virar um Tensor com tamanho (batch_size, 1)\n",
    "        loss = loss_fn(y_pred, y.unsqueeze_(1))\n",
    "        \n",
    "        # Zera os gradientes antes da Retro-propagação (Backpropagation)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Retro-propagação (Backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualização dos parâmetros\n",
    "        optimizer.step()\n",
    "\n",
    "    # Fim da Época\n",
    "    print(f\"\"\"Época {t + 1},\n",
    "          Custo Treino: {round(loss.item(), 3)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f21e53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de Treino: 0.6000000238418579\n",
      "\n",
      " ---------------------------\n",
      "\n",
      "Acurácia de Teste: 0.6033519506454468\n"
     ]
    }
   ],
   "source": [
    "model.eval() # coloca o modelo em modo de avaliação (sem calcular gradientes)\n",
    "\n",
    "train_pred = model(X_train)\n",
    "train_pred = train_pred.detach().apply_(lambda x : 1 if x > 0.5 else 0)\n",
    "train_acc = torch.sum(train_pred.flatten() == y_train) / train_pred.size(0)\n",
    "\n",
    "test_pred = model(X_test)\n",
    "test_pred = test_pred.detach().apply_(lambda x : 1 if x > 0.5 else 0)\n",
    "test_acc = torch.sum(test_pred.flatten() == y_test) / test_pred.size(0)\n",
    "\n",
    "print(f\"Acurácia de Treino: {train_acc}\")\n",
    "print('\\n ---------------------------\\n')\n",
    "print(f\"Acurácia de Teste: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
